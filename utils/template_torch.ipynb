{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with data\n",
    "-----------------\n",
    "PyTorch has two primitives to work with data:<br>\n",
    "torch.utils.data.DataLoader: wraps an iterable around the Dataset<br>\n",
    "torch.utils.data.Dataset: stores the samples and their corresponding labels\n",
    "\n",
    "PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio,\n",
    "that provide a number of pre-loaded datasets:<br>\n",
    "Image Datasets: pytorch.org/vision/stable/datasets,<br>\n",
    "Text Datasets: pytorch.org/text/stable/datasets,<br>\n",
    "Audio Datasets: pytorch.org/audio/stable/datasets<br>\n",
    "\n",
    "they subclass torch.utils.data.Dataset and implement functions specific to the particular data\n",
    "\n",
    "torchvision.datasets module<br>\n",
    "-contains Dataset objects for many real-world vision data like FashionMNIST, CIFAR, COCO, etc.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms\n",
    "- are used to perform some manipulation of the data and make it suitable for training\n",
    "- all TorchVision datasets have two parameters<br>\n",
    "transform: to modify the samples,<br>\n",
    "target_transform: to modify the labels\n",
    "- the `torchvision.transforms` module offers several commonly-used transforms out of the box\n",
    "\n",
    "The FashionMNIST features are in PIL Image format, and the labels are integers.\n",
    "For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
    "\n",
    "ToTensor(): converts a PIL image or NumPy ``ndarray`` into a ``FloatTensor`` and scales\n",
    "the image's pixel intensity values in the range [0., 1.]\n",
    "\n",
    "user-defined lambda function:<br>\n",
    "- here, we define a function to turn the integer into a one-hot encoded tensor\n",
    "- it first creates a zero tensor of size 10 (the number of labels in our dataset) and calls\n",
    "scatter_ which assigns a ``value=1`` on the index as given by the label ``y``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot\n",
    "#target_transform = Lambda(lambda y: torch.zeros(\n",
    "#    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor(),)\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the Dataset as an argument to DataLoader - this wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating the Dataset\n",
    "\n",
    "iteration/indexing: a list training_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Custom Dataset for your files\n",
    "---------------------------------------------------\n",
    "A custom Dataset class must implement three functions:.<br>\n",
    "``__init__``: is run once when instantiating the Dataset object. We initialize\n",
    "the directory containing the images, the annotations file, and both transforms.\n",
    "\n",
    "``__len__``: returns the number of samples in our dataset\n",
    "\n",
    "``__getitem__``: loads and returns a sample from the dataset at the given index ``idx``.<br>\n",
    "Based on the index, it identifies the image's location on disk, converts that to a tensor using ``read_image``, retrieves the corresponding label from the csv data in ``self.img_labels``, calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple.\n",
    "\n",
    "Here: the FashionMNIST images are stored in a directory ``img_dir``, and their labels are stored separately in a CSV file ``annotations_file``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        #self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing your data for training with DataLoaders\n",
    "-------------------------------------------------\n",
    "The ``Dataset`` retrieves our dataset's features and labels one sample at a time.<br>\n",
    "While training a model, we typically want to pass samples in \"minibatches\", reshuffle the data at every epoch to reduce model overfitting, and use Python's ``multiprocessing`` to speed up data retrieval.\n",
    "\n",
    "``DataLoader`` is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the DataLoader\n",
    "--------------------------\n",
    "\n",
    "We have loaded that dataset into the ``DataLoader`` and can iterate through the dataset as needed.\n",
    "Each iteration below returns a batch of ``train_features`` and ``train_labels`` (containing ``batch_size=64`` features and labels respectively).\n",
    "Because we specified ``shuffle=True``, after we iterate over all batches the data is shuffled (for finer-grained control over\n",
    "the data loading order, take a look at `Samplers <https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler>`_).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters\n",
    "-----------------\n",
    "\n",
    "Hyperparameters are adjustable parameters that let you control the model optimization process.\n",
    "Different hyperparameter values can impact model training and convergence rates.\n",
    "\n",
    "We define the following hyperparameters for training:\n",
    " - **Number of Epochs** - the number times to iterate over the dataset\n",
    " - **Batch Size** - the number of data samples propagated through the network before the parameters are updated\n",
    " - **Learning Rate** - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 1e-3\n",
    "#batch_size = 64\n",
    "#epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "\n",
    "print(X.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Models\n",
    "------------------\n",
    "To define a neural network in PyTorch, we create a class that inherits from nn.Module.<br>\n",
    "We define the layers of the network in the ``__init__`` function.<br>\n",
    "We specify how data will pass through the network in the forward function.<br>\n",
    "To accelerate operations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "#nn.Sequential is an ordered container of modules\n",
    "#The data is passed through all the modules in the same order as defined\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),      #is applied after linear transformations to introduce nonlinearity\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "#The last linear layer of the neural network returns `logits` - raw values in [-\\infty, \\infty]\n",
    "#when they are passed to the `nn.Softmax` module, they got scaled to values [0, 1]\n",
    "#representing the model's predicted probabilities for each class.\n",
    "#dim parameter indicates the dimension along which the values must sum to 1.\n",
    "\n",
    "\n",
    "#Do not call model.forward() directly!\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "#we create an instance of NeuralNetwork, and move it to the device, and print its structure\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n",
      "Before ReLU: tensor([[ 0.4744, -0.0531, -0.0910,  0.4040, -0.2918,  0.0881, -0.6167, -0.2391,\n",
      "         -0.1788,  0.1536, -0.0908, -0.2957,  0.0868, -0.1355,  0.1971, -0.1443,\n",
      "          0.0940,  0.1610,  0.2328,  0.4784],\n",
      "        [ 0.8194,  0.2368,  0.2059,  0.0772, -0.2923,  0.0086, -0.8330, -0.3690,\n",
      "         -0.0980, -0.2269, -0.0968, -0.6648, -0.3732, -0.0360, -0.6289, -0.3586,\n",
      "          0.2295,  0.1855,  0.5291,  0.6245],\n",
      "        [ 0.5809, -0.0479,  0.0466,  0.2181,  0.0204,  0.3441, -0.4724,  0.0562,\n",
      "         -0.1250,  0.2688, -0.0380, -0.5037,  0.2623, -0.3303, -0.3001, -0.2192,\n",
      "          0.1725, -0.0605,  0.5609,  0.6825]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.4744, 0.0000, 0.0000, 0.4040, 0.0000, 0.0881, 0.0000, 0.0000, 0.0000,\n",
      "         0.1536, 0.0000, 0.0000, 0.0868, 0.0000, 0.1971, 0.0000, 0.0940, 0.1610,\n",
      "         0.2328, 0.4784],\n",
      "        [0.8194, 0.2368, 0.2059, 0.0772, 0.0000, 0.0086, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2295, 0.1855,\n",
      "         0.5291, 0.6245],\n",
      "        [0.5809, 0.0000, 0.0466, 0.2181, 0.0204, 0.3441, 0.0000, 0.0562, 0.0000,\n",
      "         0.2688, 0.0000, 0.0000, 0.2623, 0.0000, 0.0000, 0.0000, 0.1725, 0.0000,\n",
      "         0.5609, 0.6825]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#input_image = torch.rand(3,28,28)\n",
    "#print(input_image.size())\n",
    "\n",
    "#flatten = nn.Flatten()\n",
    "#flat_image = flatten(input_image)\n",
    "#print(flat_image.size())\n",
    "\n",
    "#layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "#hidden1 = layer1(flat_image)\n",
    "#print(hidden1.size())\n",
    "\n",
    "#print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "#hidden1 = nn.ReLU()(hidden1)\n",
    "#print(f\"After ReLU: {hidden1}\")\n",
    "\n",
    "#seq_modules = nn.Sequential(\n",
    "#    flatten,\n",
    "#    layer1,\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(20, 10)\n",
    "#)\n",
    "#input_image = torch.rand(3,28,28)\n",
    "#logits = seq_modules(input_image)\n",
    "\n",
    "#softmax = nn.Softmax(dim=1)\n",
    "#pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing the Model Parameters\n",
    "----------------------------------------\n",
    "To train a model, we need a loss function and an optimizer and pass it to train loop and test loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "- measures the degree of dissimilarity of obtained result to the target value\n",
    "- is minimized during training\n",
    "- to calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value\n",
    "\n",
    "Common loss functions include `nn.MSELoss` (Mean Square Error) for regression tasks, and\n",
    "`nn.NLLLoss`(Negative Log Likelihood) for classification.\n",
    "`nn.CrossEntropyLoss` combines ``nn.LogSoftmax`` and ``nn.NLLLoss``.\n",
    "\n",
    "We pass our model's output logits to ``nn.CrossEntropyLoss``, which will normalize the logits and compute the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "- Optimization: the process of adjusting model parameters to reduce model error in each training step.\n",
    "- Optimization algorithms define how this process is performed: SGD, ADAM, RMSProp\n",
    "- All optimization logic is encapsulated in the optimizer object.\n",
    "- We initialize the optimizer by registering the model's parameters that need to be trained, and passing in the learning rate hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model is an iterative process; in each iteration (called an *epoch*) the model makes a guess about the output, calculates the error in its guess (*loss*), collects the derivatives of the error with respect to its parameters, and **optimizes** these parameters using gradient descent.\n",
    "\n",
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define train method that loops over our optimization code\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "# Backpropagation---\n",
    "\n",
    "#Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "#-Call optimizer.zero_grad() to reset the gradients of model parameters. \n",
    "# Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#Backpropagate the prediction loss with a call to loss.backwards().\n",
    "#PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "        loss.backward()\n",
    "\n",
    "#Once we have our gradients, we call optimizer.step() to adjust the parameters\n",
    "#by the gradients collected in the backward pass.\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model's performance against the test dataset to ensure it is learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define test_loop that evaluates the model's performance against our test data\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations *epochs*.<br>\n",
    "During each epoch, the model learns parameters to make better predictions.<br>\n",
    "We print the model's accuracy and loss at each epoch; we'd like to see the\n",
    "accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.304628  [    0/60000]\n",
      "loss: 2.294384  [ 6400/60000]\n",
      "loss: 2.265129  [12800/60000]\n",
      "loss: 2.260792  [19200/60000]\n",
      "loss: 2.263097  [25600/60000]\n",
      "loss: 2.219875  [32000/60000]\n",
      "loss: 2.238781  [38400/60000]\n",
      "loss: 2.202724  [44800/60000]\n",
      "loss: 2.198529  [51200/60000]\n",
      "loss: 2.168016  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 2.160757 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.172502  [    0/60000]\n",
      "loss: 2.163223  [ 6400/60000]\n",
      "loss: 2.103494  [12800/60000]\n",
      "loss: 2.121705  [19200/60000]\n",
      "loss: 2.090804  [25600/60000]\n",
      "loss: 2.016382  [32000/60000]\n",
      "loss: 2.054311  [38400/60000]\n",
      "loss: 1.977199  [44800/60000]\n",
      "loss: 1.988357  [51200/60000]\n",
      "loss: 1.919157  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.912246 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.945292  [    0/60000]\n",
      "loss: 1.915265  [ 6400/60000]\n",
      "loss: 1.804762  [12800/60000]\n",
      "loss: 1.844501  [19200/60000]\n",
      "loss: 1.749438  [25600/60000]\n",
      "loss: 1.689220  [32000/60000]\n",
      "loss: 1.719785  [38400/60000]\n",
      "loss: 1.621941  [44800/60000]\n",
      "loss: 1.654159  [51200/60000]\n",
      "loss: 1.550530  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.557921 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.626962  [    0/60000]\n",
      "loss: 1.585515  [ 6400/60000]\n",
      "loss: 1.443877  [12800/60000]\n",
      "loss: 1.505144  [19200/60000]\n",
      "loss: 1.395800  [25600/60000]\n",
      "loss: 1.381342  [32000/60000]\n",
      "loss: 1.395130  [38400/60000]\n",
      "loss: 1.319348  [44800/60000]\n",
      "loss: 1.357085  [51200/60000]\n",
      "loss: 1.257907  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.276471 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.357462  [    0/60000]\n",
      "loss: 1.334530  [ 6400/60000]\n",
      "loss: 1.173268  [12800/60000]\n",
      "loss: 1.265843  [19200/60000]\n",
      "loss: 1.151703  [25600/60000]\n",
      "loss: 1.166775  [32000/60000]\n",
      "loss: 1.183466  [38400/60000]\n",
      "loss: 1.121992  [44800/60000]\n",
      "loss: 1.163548  [51200/60000]\n",
      "loss: 1.079996  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.096214 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#To use the model, we pass it the input data.\n",
    "#This executes the model's forward, along with some background operations.\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters\n",
    "\n",
    "Many layers inside a neural network are *parameterized*, i.e. have associated weights\n",
    "and biases that are optimized during training. Subclassing ``nn.Module`` automatically\n",
    "tracks all fields defined inside your model object, and makes all parameters\n",
    "accessible using your model's ``parameters()`` or ``named_parameters()`` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0088,  0.0262,  0.0222,  ...,  0.0094, -0.0259,  0.0302],\n",
      "        [ 0.0038,  0.0280, -0.0059,  ..., -0.0048, -0.0105,  0.0110]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0288, 0.0117], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0031, -0.0355,  0.0138,  ...,  0.0163, -0.0347, -0.0028],\n",
      "        [-0.0231,  0.0393, -0.0342,  ...,  0.0415, -0.0366, -0.0185]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0280, -0.0365], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0370,  0.0015,  0.0042,  ..., -0.0170,  0.0241, -0.0423],\n",
      "        [-0.0172, -0.0227,  0.0425,  ...,  0.0049, -0.0111,  0.0190]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0037,  0.0659], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models Weights\n",
    "-------------\n",
    "save a model (the learned parameters) = serialize the internal state dictionary ``state_dict`` (containing the model parameters)<br>\n",
    "method: ``torch.save``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# model = models.vgg16(pretrained=True) #jakiś pretrenowany model \n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models Weights\n",
    "----------------------------\n",
    "To load model weights, you need to create an instance of the same model first, and then load the parameters using ``load_state_dict()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()  # do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We might want to save the structure of this class together with the model, \n",
    "#in which case we can pass model (and not model.state_dict()) to the saving function:\n",
    "torch.save(model, 'model.pth')\n",
    "\n",
    "#We can then load the model like this:\n",
    "model = torch.load('model.pth')\n",
    "\n",
    "#This approach uses Python pickle module when serializing the model, \n",
    "#thus it relies on the actual class definition to be available when loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = torch.rand(1, 28, 28, device=device)\n",
    "#logits = model(X)\n",
    "#pred_probab = nn.Softmax(dim=1)(logits)\n",
    "#y_pred = pred_probab.argmax(1)\n",
    "#print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Reading\n",
    "-----------------------\n",
    "- `Saving and Loading a General Checkpoint in PyTorch <https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html>`_\n",
    "- `Loss Functions <https://pytorch.org/docs/stable/nn.html#loss-functions>`_\n",
    "- `torch.optim <https://pytorch.org/docs/stable/optim.html>`_\n",
    "- `Warmstart Training a Model <https://pytorch.org/tutorials/recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.html>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
